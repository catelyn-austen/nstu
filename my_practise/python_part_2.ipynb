{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка файлов\n",
    "* csv [comma separated values] - формат, в котором данные отделены запятыми\n",
    "* pd.read_csv('file', sep='разделитель', index_col='название'/номер столбца) - чтение файла и создание датафрейма, где index_col - то, что мы хотим, чтобы оно выступало в кач-ве индекса в датафрейме\n",
    "* pd.to_csv('file', sep='разделитель', index_label='название'/номер столбца) - запись датафрейма в файл, где sep - новый разделитель, index_label - столбец с индексом\n",
    "\n",
    "#### Дата\n",
    "* в pandas даты стандартизированы: год-месяц-день. так легче анализировать и сравнивать\n",
    "* pandas может сам найти год в дате, но день и месяц нужно определить самому (посмотрев на данные)\n",
    "* если первым идет день, то задаем параметр (в read_csv) dayfirst, который равен True, иначе False (если первым идет месяц)\n",
    "* чтобы определить столбец с датами, нужно в read_csv указать метод parse_dates=['столбец с датой']\n",
    "* можно определить день недели методом df['Week_day'] = df['Date'].dt.day_name()\n",
    "\n",
    "#### XLXS\n",
    "* файлики, не читабельные в блокноте, но читабельные в экселе\n",
    "* pd.read_excel('file', sep=, sheet_name='название листа', parse_dates=[''], dayfirst=) - чтение\n",
    "* df.to_excel('file', index_label=, sep=) - запись\n",
    "\n",
    "#### JSON\n",
    "* для работы с json нужна библиотека с соотв. названием\n",
    "* name = json.dump(dict) - перевод объекта типа словарь в текстовую строку\n",
    "* name = json.loads(str) - перевод объекта типа строка в словарь\n",
    "\n",
    "#### Pickle\n",
    "* это бинарный формат хранения данных\n",
    "* import pickle\n",
    "* работа с pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# открытие файла на запись\n",
    "import pickle\n",
    "\n",
    "dic = {'Haha': 45}\n",
    "with open('/file.pkl', 'wb') as f: # wb - на бинарную запись\n",
    "    pickle.dump(dic, f)\n",
    "\n",
    "# открытие файла на чтение и сохранение в словарь\n",
    "with open('/file.pkl', 'rb') as f1:\n",
    "    dic1 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 (Иерархический формат данных)\n",
    "* улучшенная версия модуля pickle\n",
    "* этот формат позволяет читать данные по кускам и не загружать всё\n",
    "* pandas работает с этим форматом\n",
    "* этот формат спроектирован для хранения многомерных массивов\n",
    "\n",
    "# Выгрузка из БД\n",
    "\n",
    "#### SQLite3\n",
    "* библиотека для работы с БД\n",
    "* soed = sqlite3.connect('file.db') - подключение к БД (к файлу, который представляет БД)\n",
    "* c = name.cursor() - обхект, служащий для доступа к таблицам\n",
    "* c.execute('''запрос''') - выполнение запроса на sql\n",
    "* soed.commit() - сохранение изменений\n",
    "* soed.close() - закрытие соединения\n",
    "* c.executemany('''запрос''', dataset) - запрос на добавление данных datasetа в таблицу?\n",
    "\n",
    "# выгрузка с postgresа дольше, тк мы запрашиваем данные с сервера, а не с файла, как в sqlite3\n",
    "\n",
    "#### PostgreSQL\n",
    "* import psycopg2\n",
    "* pg_connection = { 'host': '',\n",
    "                    'port': int,\n",
    "                    'dbname': '',\n",
    "                    'user': '',\n",
    "                    'password': ''} - подключение как словарь\n",
    "* con = psycopg2.connect(**pg_connection)\n",
    "* c = con.cursor()\n",
    "* c.execute('запрос')\n",
    "* c.fetchall() - метод курсора, возвращающий все строки из запроса\n",
    "\n",
    "# Вот тут и ответ на мой вопрос, как выгружать данные\n",
    "#### pandas\n",
    "* сначала нужно создать соединение с помощью sclite3, затем использовать это соединение так:\n",
    "* df = pd.read_sql_query('запрос', con) - тупо взятие того, что вышло после запроса в df\n",
    "* pandas выгружает только небольшое количество данных, поэтому его не всегда удобно использовать\n",
    "\n",
    "# Нереляц. БД\n",
    "\n",
    "#### MongoDB\n",
    "* import pymongo\n",
    "* pg_connection = { 'host': '',\n",
    "                    'port': int,\n",
    "                    'dbname': '',\n",
    "                    'user': '',\n",
    "                    'password': '',\n",
    "                    'authSource': ''} - последнее - это таблица (коллекция)\n",
    "* само подключение:\n",
    "mongo = MongoClient('mongodb://user:password@host:port/?authSource=authSource')\n",
    "* db = mongo['name'] - явный вид\n",
    "* db.list_collection_names() - посмотреть доступные коллекции\n",
    "* coll = db['name'] - коллекция\n",
    "* coll.estimated_document_count() - посмотреть количество документов\n",
    "* c = coll.find().limit(num) - создание курсора. в данном примере берутся 5 строк\n",
    "* selector = {'' : T / F} - словарь, который нужен, чтобы в find(projection=selector) выводить только то, что нам нужно\n",
    "* find(filter={'name': 'toy'}) - хотим оставить только фильмы, содержащие тэг toy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа со строками\n",
    "* import string - библиотека для работы со строками\n",
    "* из датасета элемент можно взять и так: df.column_name.value[num]\n",
    "* text.lower() - приведение к нижнему регистру\n",
    "* string.punctuation - элементы пунктуации, то есть строка состоящая из непрерывно идущих знаков !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "k a k a\n",
      "ab, cd, ef\n",
      "Я хотела бы чтобы был мир worldyaru во всем мире\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text = 'Я хотела бы, чтобы был мир world@ya.ru во всем мире.'\n",
    "print(string.punctuation)\n",
    "print(\" \".join('kaka'))\n",
    "print(\", \".join(['ab', 'cd', 'ef']))\n",
    "\n",
    "# убираем знаки препинания везде\n",
    "print(\"\".join([i for i in text if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Регулярные выражения\n",
    "* позволяют извлекать из текста сложную информацию\n",
    "* как на методах трансляции, РВ - правила записи / извлечения этой инфы из всего текста\n",
    "* для анализа РВ применяются, чтобы извлечь из текста email, номера телефонов, например, и тп и тд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 're.Pattern'>\n",
      "['world@ya.ru']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "reg_expr = r'\\w+@\\w+.\\w+' # обязательно ставить r, чтобы дать питону понять, что это не просто строка, а РВ\n",
    "reg_expr_compiled = re.compile(reg_expr)\n",
    "print(type(reg_expr_compiled))\n",
    "\n",
    "# проверяем исходный текст по созданному нами шаблону РВ\n",
    "res = reg_expr_compiled.findall(text)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выражения\n",
    "* . - любой символ\n",
    "* \\w - любая буква\n",
    "* \\W - все, что не входит в \\w\n",
    "* \\d - любая цифра\n",
    "* \\D\n",
    "* \\b - граница слова\n",
    "* [...] - любой из перечисленных символов\n",
    "\n",
    "#### Квантификаторы - указание на кол-во\n",
    "* '+' - одно или более вхождений\n",
    "* '*' - 0 или более вхождений\n",
    "* {m,n} - от m до n вх\n",
    "* {n} - ровно n вх\n",
    "* \\s - пробельный символ (таб, например)\n",
    "* ^ - начало вх\n",
    "* $ - конец вх\n",
    "* () - группирующие скобки, позволяющие искать подстроки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "not ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# телефоны\n",
    "tels = ['79999999999', '9999999-999', '89132504956']\n",
    "for el in tels:\n",
    "    if re.match(r'[7-8]{1}[0-9]{9}', el) and len(el) == 11:\n",
    "        print('ok')\n",
    "    else:\n",
    "        print('not ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### match и findall\n",
    "* match возвращает да или нет\n",
    "* findall возваращает элементы списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нормализация слов (приведение к начальной форме слова)\n",
    "* здесь потребуется библиотека pymorphy2, которая создана для работы с морфемами языка\n",
    "* она помогает приводить слово к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['я', 'хотеть', 'покушать', 'ягода', 'сильный', 'чем', 'питон', 'хотеть']\n"
     ]
    }
   ],
   "source": [
    "import pymorphy3\n",
    "\n",
    "normal = []\n",
    "token_list = ['Я', 'хочу', 'покушать', 'ягод', 'сильней', 'чем', 'питон', 'хочет']\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "for word in token_list:\n",
    "    parsed_token = morph.parse(word)\n",
    "    normal_form = parsed_token[0].normal_form\n",
    "    normal.append(normal_form)\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Статистики текста (с pandas)\n",
    "* оценим количество наиболее часто встречаемых слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>он</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>босс</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>герой</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>на</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>как</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>который</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>помощь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>очень</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>по</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>повышение</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  co\n",
       "20         он   2\n",
       "1        босс   2\n",
       "4       герой   2\n",
       "15         на   2\n",
       "9         как   2\n",
       "13    который   2\n",
       "26     помощь   1\n",
       "22      очень   1\n",
       "23         по   1\n",
       "24  повышение   1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# приводим текст к нормальному виду, изначально разделив его на слова\n",
    "text = 'Отгадайте, как называется старый советский фильм, в котором главный герой претендует на повышение по службе, но очень боится своего босса, а босс даже не помнит его имени. На помощь герою приходит его коллега, который советует использовать такую карьерную компетенцию как мужское обаяние.'\n",
    "reg_expr = r'\\w+'\n",
    "reg_expr_compiled = re.compile(reg_expr)\n",
    "res = reg_expr_compiled.findall(text)\n",
    "\n",
    "normal = []\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "for word in res:\n",
    "    parsed_token = morph.parse(word)\n",
    "    normal_form = parsed_token[0].normal_form\n",
    "    normal.append(normal_form)\n",
    "\n",
    "# создаем датафрейм и добавляем единички для счетчика\n",
    "df = pd.DataFrame(normal)\n",
    "df.columns = ['Word']\n",
    "df['co'] = 1\n",
    "df.head()\n",
    "\n",
    "# подсчитываем количество слов и выбираем 10 самых частых\n",
    "word_c = df.groupby('Word')['co'].count().reset_index()\n",
    "#word_c.head()\n",
    "word_c.sort_values(['co'], ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
